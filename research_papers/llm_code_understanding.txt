Title: Using an LLM to Help With Code Understanding

Abstract: Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.

Introduction: Building and maintaining software systems requires a deep understanding of a codebase. Consequently, developers spend a significant amount of time searching and foraging for the information they need. Understanding code, however, is a challenging task; developers need to assimilate a large amount of information about the semantics of the code, the intricacies of the APIs used, and the relevant domain-specific concepts. Such information is often scattered, inadequately documented, or outdated.

With the growing popularity of LLM-based code generation tools, the need for code understanding support is arguably growing even higher, as developers may receive code they don't understand. Fortunately, LLMs also provide an opportunity in this space. To explore this, we developed a prototype in-IDE LLM information support tool, GILT (Generation-based Information-support with LLM Technology). GILT generates on-demand information while considering the user's local code context. We introduce a "prompt-less" interaction method to alleviate the cognitive load of writing good prompts.

Methodology: We developed GILT, a VS Code IDE plugin using GPT-3.5-turbo. GILT provides code understanding support through two interaction methods: "prompt-less" buttons (to explain code, APIs, concepts, or show usage) and direct, open-ended queries that automatically use highlighted code as context.

We conducted a user study with 32 participants (16 students, 16 professionals) to compare GILT against traditional web search. The study used a within-subjects design where participants had to understand and modify unfamiliar Python code using Bokeh (data visualization) and Open3d (3D rendering) libraries. We measured task completion rates, time, code understanding (via quizzes), and user perceptions (using Technology Acceptance Model and NASA-TLX surveys).

Results: Participants using GILT had a statistically significant higher task completion rate compared to those using web search. However, there were no significant differences in task completion time or code understanding scores. The benefits were significant for professionals but not for students.

Professionals were more successful with direct text prompts and demonstrated better prompt engineering skills, while students relied more on the "prompt-less" buttons. Users perceived GILT as significantly more useful and easier to use than web search. They also felt less rushed and more successful in accomplishing their tasks. The most praised feature was the automatic inclusion of code context, which saved time and effort, although some participants still struggled to write effective prompts.

Conclusion: We presented the results of a user study that aimed to investigate the effectiveness of generation-based information support using LLMs to aid developers in code understanding. With our in-IDE prototype tool, GILT, we demonstrated that this approach significantly enhances developers' ability to complete tasks compared to traditional search-based information seeking. At the same time, we also identified that the degree of benefits developers can get from the tool differs between students and professionals, and the way developers interact with the tool varies based on their learning styles and familiarity with other AI tools.

References: 
[1] Amoozadeh, M., et al. (2023). Trust in Generative Al among students: An Exploratory Study. arXiv:2310,04631. [2] Barke, S., James, M. B., & Polikarpova, N. (2023). Grounded Copilot: How Programmers Interact with Code-Generating Models. Proc. ACM Program. Lang. [3] Barnaby, C., et al. (2020). Exempla Gratis (E.G.): Code Examples for Free. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference (ESEC/FSE 2020). [4] Beckwith, L., et al. (2006). Tinkering and gender in end-user programmers debugging. In Proceedings of the 2006 Conference on Human Factors in Computing Systems (CHI 2006). [5] Bokeh. (2023). Bokeh. https://bokeh.org/